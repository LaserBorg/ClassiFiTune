{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "91JqhpJQMmhM"
      },
      "source": [
        "\n",
        "Finetuning Torchvision Models\n",
        "=============================\n",
        "[original tutorial](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html) ([cs231n](https://cs231n.github.io/transfer-learning)) | [models](https://pytorch.org/vision/stable/models.html) | [datasets](https://pytorch.org/vision/stable/datasets.html)\n",
        "\n",
        "TODO:\n",
        "* try resolution > 224 ([discussion](https://discuss.pytorch.org/t/transfer-learning-usage-with-different-input-size/20744/6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayI_34cTMmhR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "#from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Helper Functions\n",
        "from libs.model_definitions import initialize_model\n",
        "from libs.train_model import train_model\n",
        "from libs.dataset_utils import get_transforms\n",
        "from libs import splitfolders\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "SAyt1jy-MmhT"
      },
      "outputs": [],
      "source": [
        "raw_data_dir = \"./dataset/_raw/\"\n",
        "split_data_dir = \"./dataset/\"  # [train, val, test] dirs\n",
        "split_ratio = (.8, .1, .1)  # train, val, test split\n",
        "copy_dataset = True  # copy or move files\n",
        "\n",
        "# ImageNet normalization\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "# number of data loader workers\n",
        "dloader_workers = 6\n",
        "\n",
        "model_list =    [\"resnet18\", \"resnet50\", \"alexnet\", \"vgg11_bn\", \"squeezenet\", \"densenet121\", \"inception_v3\", \"mobilenet_v2\", \n",
        "                \"mobilenet_v3_large\", \"regnet_y_16gf\", \"efficientnet_v2_s\", \"efficientnet_v2_m\", \"convnext_base\", \"swin_v2_b\"]\n",
        "\n",
        "# select model type\n",
        "model_type = \"mobilenet_v3_large\"\n",
        "\n",
        "model_name = \"mobilenet_v3_large\"\n",
        "checkpoints_dir = \"checkpoints/\"\n",
        "checkpoint_path = os.path.join(checkpoints_dir, model_name + \".pt\")\n",
        "\n",
        "# metadata\n",
        "json_path = os.path.join(checkpoints_dir, model_name + \"_metadata.json\")\n",
        "\n",
        "# include softmax layer in model\n",
        "add_softmax = False\n",
        "\n",
        "# Feature Augmentation\n",
        "scale_range = (0.75, 1.2)\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 50\n",
        "\n",
        "# Number of epochs to train for \n",
        "num_epochs = 20\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "optimizer_name = \"adam\"  # [adam, sgd]\n",
        "\n",
        "# train all layers or just head layer\n",
        "train_deep = True\n",
        "\n",
        "# check if model_type exists\n",
        "if not model_type in model_list:\n",
        "    print(f\"ERROR: model {model_type} unknown!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if dataset is already splitted\n",
        "if not splitfolders.check_existence(split_data_dir, dirs=[\"val\", \"test\", \"train\"]):\n",
        "\n",
        "    # copy or move dataset split into train, validation and test\n",
        "    splitfolders.ratio(raw_data_dir, output=split_data_dir, \n",
        "                       seed=1337, ratio=split_ratio,\n",
        "                       group_prefix=None, \n",
        "                       move=not(copy_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Number of classes in the dataset\n",
        "\n",
        "def count_directories(path):\n",
        "    return len([name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))])\n",
        "\n",
        "num_classes = count_directories(os.path.join(split_data_dir, \"train\"))\n",
        "print(f\"Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------------\n",
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## initialize model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the model for this run\n",
        "model, input_size = initialize_model(model_type, num_classes, train_deep, add_softmax=add_softmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "replace Colab imshow with custom function for use in Jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_tensor_to_array(image, idx=0):\n",
        "    # from libs.dataset_utils import convert_image_to_cv\n",
        "    # img = convert_image_to_cv(image, RGB2BGR=False, normalized=True)\n",
        "\n",
        "    img = image.cpu().data[idx].numpy().transpose((1, 2, 0))  # [-1 |  1 ]\n",
        "    img = std * img + mean  # denormalize\n",
        "    img = np.clip(img*255, 0, 255).astype(np.uint8)  # convert to uint8\n",
        "    return img"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G6ozpb87Mmha"
      },
      "source": [
        "### Load Data\n",
        "----------------\n",
        "Now that we know what the input size must be, we can initialize the data\n",
        "transforms, image datasets, and the dataloaders. Notice, the models were\n",
        "pretrained with the hard-coded normalization values, as described\n",
        "`here <https://pytorch.org/docs/master/torchvision/models.html>`__.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugCvPxB_Mmhb"
      },
      "outputs": [],
      "source": [
        "# Data augmentation and normalization for training: http://pytorch.org/vision/main/transforms.html\n",
        "# TODO: or use https://albumentations.ai instead\n",
        "data_transforms = get_transforms(input_size, scale_range=scale_range, hflip=0.5, mean=mean, std=std)\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(split_data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=dloader_workers) for x in ['train', 'val']}\n",
        "\n",
        "class_labels = image_datasets['train'].classes\n",
        "print(\"class_labels:\", class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imshow(image, title=None):\n",
        "    if not isinstance(image, np.ndarray):\n",
        "        image = convert_tensor_to_array(image)\n",
        "\n",
        "    ax = plt.subplot(2, 2, 1)\n",
        "    ax.axis('off')\n",
        "    if title:\n",
        "        ax.set_title(title)\n",
        "    plt.imshow(image)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "\n",
        "def visualize_model(model, device=device, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders_dict['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            top_probs, top_labels = torch.max(probabilities, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "\n",
        "                class_label = class_labels[top_labels[j]]\n",
        "                probability = top_probs[j].cpu().numpy()\n",
        "                ax.set_title(f'predicted: {class_label} ({probability:.2f})')\n",
        "\n",
        "                img = convert_tensor_to_array(inputs, idx=j)\n",
        "                plt.imshow(img)\n",
        "            \n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "                \n",
        "        model.train(mode=was_training)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C81WMAgAMmhb"
      },
      "source": [
        "## Create the Optimizer\n",
        "--------------------\n",
        "\n",
        "Now that the model structure is correct, the final step for finetuning\n",
        "and feature extracting is to create an optimizer that only updates the\n",
        "desired parameters. Recall that after loading the pretrained model, but\n",
        "before reshaping, if ``train_deep=False`` we manually set all of the\n",
        "parameter’s ``.requires_grad`` attributes to False. Then the\n",
        "reinitialized layer’s parameters have ``.requires_grad=True`` by\n",
        "default. So now we know that *all parameters that have\n",
        ".requires_grad=True should be optimized.* Next, we make a list of such\n",
        "parameters and input this list to the SGD algorithm constructor.\n",
        "\n",
        "To verify this, check out the printed parameters to learn. When\n",
        "finetuning, this list should be long and include all of the model\n",
        "parameters. However, when feature extracting this list should be short\n",
        "and only include the weights and biases of the reshaped layers.\n",
        "\n",
        "--------------------\n",
        "[using Adam instead of SGD](https://analyticsindiamag.com/ultimate-guide-to-pytorch-optimizers/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-oSayW1jMmhb"
      },
      "outputs": [],
      "source": [
        "# Send the model to GPU if possible\n",
        "model = model.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are \n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model.parameters()\n",
        "#print(\"Params to learn:\")\n",
        "if not train_deep:\n",
        "    params_to_update = []\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            #print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            #print(\"\\t\",name)\n",
        "            continue\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "if optimizer_name == \"adam\":\n",
        "    optimizer_ft = optim.Adam(params_to_update, lr=learning_rate)\n",
        "else:\n",
        "    optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W4gDImEUMmhc"
      },
      "source": [
        "## Run Training and Validation Step\n",
        "--------------------------------\n",
        "\n",
        "Finally, the last step is to setup the loss for the model, then run the\n",
        "training and validation function for the set number of epochs. Notice,\n",
        "depending on the number of epochs this step may take a while on a CPU.\n",
        "Also, the default learning rate is not optimal for all of the models, so\n",
        "to achieve maximum accuracy it would be necessary to tune for each model\n",
        "separately.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEsbBll7Mmhc"
      },
      "outputs": [],
      "source": [
        "# Setup the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "starttime = time.time()\n",
        "\n",
        "# Train and evaluate\n",
        "model, hist = train_model(model, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, device=device)\n",
        "\n",
        "training_duration = time.time() - starttime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_val_acc = round(float(max(hist)), 4)\n",
        "last_val_acc = round(float(hist[-1]), 4)\n",
        "\n",
        "print(\"best_val_acc:\", best_val_acc)\n",
        "print(\"last_val_acc:\", last_val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_model(model, device=device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Checkpoint\n",
        "[saving and loading checkpoints tutorial](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html) , [stackoverflow](https://stackoverflow.com/questions/42703500/how-do-i-save-a-trained-model-in-pytorch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get current date and time as string\n",
        "def get_current_date():\n",
        "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
        "\n",
        "# write model metadata to json file\n",
        "def save_json(data, json_path, update=True):\n",
        "\n",
        "    if update:\n",
        "        with open(json_path) as f:\n",
        "            data_old = json.load(f)\n",
        "        data_old.update(data)\n",
        "        data = data_old\n",
        "    \n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EPOCH = num_epochs  # TODO: current epoch / epoch of best val acc\n",
        "# LOSS = 0.4          # TODO read from hist\n",
        "#\n",
        "# torch.save({\n",
        "#             'epoch': EPOCH,\n",
        "#             'model_state_dict': model.state_dict(),\n",
        "#             'optimizer_state_dict': optimizer_ft.state_dict(),\n",
        "#             'loss': LOSS,\n",
        "#             }, checkpoint_path)\n",
        "\n",
        "torch.save(model, checkpoint_path)\n",
        "\n",
        "\n",
        "# Write variables to a JSON file\n",
        "data = {\n",
        "    'date_created':             get_current_date(),\n",
        "    'model_type':               model_type, \n",
        "    'input_size':               input_size,\n",
        "    'has_softmax':              add_softmax,\n",
        "    'class_labels':             class_labels, \n",
        "    'initial_learning_rate':    learning_rate,\n",
        "    'epochs':                   num_epochs,\n",
        "    'training_time':            training_duration,\n",
        "    'best_val_acc':             best_val_acc,\n",
        "    'last_val_acc':             last_val_acc\n",
        "    }\n",
        "\n",
        "save_json(data, json_path, update=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### convert to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "# # Define the data transformations (same as used during training)\n",
        "# data_transforms = transforms.Compose([\n",
        "#     transforms.Resize(256),\n",
        "#     transforms.CenterCrop(224),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "# ])\n",
        "\n",
        "# Load a sample image from your validation dataset\n",
        "images_dir = os.path.join(split_data_dir, \"val\")\n",
        "image_datasets = datasets.ImageFolder(images_dir, data_transforms[\"val\"])\n",
        "dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=1, shuffle=True)\n",
        "\n",
        "# Get a single batch (one image)\n",
        "inputs, _ = next(iter(dataloader))\n",
        "\n",
        "# Move the model and inputs to the same device (CPU or GPU)\n",
        "model.to(device)\n",
        "inputs = inputs.to(device)\n",
        "\n",
        "\n",
        "onnx_path = os.path.join(checkpoints_dir, model_name + \".onnx\")\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(model, inputs, onnx_path, \n",
        "                  input_names=['input'], output_names=['output'],\n",
        "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------------\n",
        "# Test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Checkpoint and Data Loader\n",
        "\n",
        "[tutorial](https://towardsdatascience.com/how-to-save-and-load-a-model-in-pytorch-with-a-complete-example-c2920e617dee)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 64\n",
        "\n",
        "# # Remember to first initialize the model and optimizer, then load the dictionary locally.\n",
        "# model, input_size = initialize_model(model_type, num_classes, train_deep)\n",
        "# model = model.to(device)\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# checkpoint = torch.load(checkpoint_path)\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# epoch = checkpoint['epoch']\n",
        "# loss = checkpoint['loss']\n",
        "\n",
        "\n",
        "model = torch.load(checkpoint_path)\n",
        "model = model.to(device)\n",
        "model.eval()  # set dropout and batch normalization layers to evaluation mode before running inference\n",
        "\n",
        "\n",
        "# create data loader for test-data\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(input_size),\n",
        "    transforms.CenterCrop(input_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dir = os.path.join(split_data_dir, \"test\")\n",
        "\n",
        "testset = datasets.ImageFolder(test_dir, test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_acc = 0.0\n",
        "for samples, labels in test_loader:\n",
        "    with torch.no_grad():\n",
        "        samples, labels = samples.to(device), labels.to(device)\n",
        "        output = model(samples)\n",
        "\n",
        "        # calculate accuracy\n",
        "        pred = torch.argmax(output, dim=1)\n",
        "        correct = pred.eq(labels)\n",
        "        test_acc += torch.mean(correct.float())\n",
        "\n",
        "testimage_count = len(testset)\n",
        "test_result = test_acc.item()/len(test_loader)\n",
        "print(f'Accuracy of the network on {testimage_count} test images: {round(test_result * 100.0, 2)}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# update metadata with test accuracy\n",
        "data = {'date_modified': get_current_date(), 'test_acc': round(test_result, 2)}\n",
        "save_json(data, json_path, update=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_model(model, device=device, num_images=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------------\n",
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def get_random_image(images_dir, ext=\".jpg\"):\n",
        "    # List all files in the directory\n",
        "    all_files = os.listdir(images_dir)\n",
        "    # Filter out only JPG files\n",
        "    jpg_files = [f for f in all_files if f.endswith(ext)]\n",
        "    # Select a random JPG file\n",
        "    random_image = random.choice(jpg_files)\n",
        "    # Return the full path to the random image\n",
        "    return os.path.join(images_dir, random_image)\n",
        "\n",
        "\n",
        "def load_pt_tensor(image_path, device=\"cpu\"):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_transformed = test_transform(image)  # = data_transforms['val'](image)\n",
        "\n",
        "    # Add a batch dimension and move to CPU/GPU\n",
        "    image_transformed = image_transformed.unsqueeze(0)  \n",
        "    return image_transformed.to(device)\n",
        "\n",
        "\n",
        "# Load class labels from a JSON file\n",
        "def load_class_labels(json_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "        class_labels = json.load(f)[\"class_labels\"]\n",
        "    return class_labels\n",
        "\n",
        "\n",
        "# get a random image from the validation set\n",
        "image_path = get_random_image(os.path.join(split_data_dir, \"val\", \"ants\"))\n",
        "\n",
        "# load class labels from metadata.json\n",
        "class_labels = load_class_labels(json_path)\n",
        "\n",
        "device = torch.device(\"cpu\")  # (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PyTorch inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def torch_predict(model, image, class_labels):\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        outputs = model(image)\n",
        "        \n",
        "        # Get the predicted class and probability\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        top_prob, top_class = probabilities.topk(1, dim=1)\n",
        "        \n",
        "        # Get the predicted class name and probability\n",
        "        class_label = class_labels[top_class[0][0]]\n",
        "        probability = top_prob[0][0].item()\n",
        "    return class_label, probability\n",
        "\n",
        "\n",
        "image_tensor = load_pt_tensor(image_path, device=device)\n",
        "\n",
        "model = torch.load(checkpoint_path)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "predicted_label, probability = torch_predict(model, image_tensor, class_labels)\n",
        "\n",
        "print(f'Predicted: {predicted_label} ({probability:.2f})')\n",
        "imshow(image_tensor, title=f'{predicted_label} ({probability:.2f})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----------\n",
        "### ONNX inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import onnxruntime as ort\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_path = os.path.join(checkpoints_dir, model_name + \".onnx\")\n",
        "ort_session = ort.InferenceSession(onnx_path)\n",
        "\n",
        "\n",
        "# Preprocess the input image\n",
        "def load_onnx_tensor(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image_tensor = test_transform(image)\n",
        "    image_tensor = image_tensor.unsqueeze(0)\n",
        "    return image_tensor\n",
        "\n",
        "\n",
        "# Run inference\n",
        "def onnx_predict(input_batch):\n",
        "    ort_inputs = {ort_session.get_inputs()[0].name: input_batch}\n",
        "    ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "    # Convert logits to probabilities\n",
        "    logits = ort_outs[0]\n",
        "    probabilities = F.softmax(torch.tensor(logits), dim=1).numpy()\n",
        "    \n",
        "    # Get the top predicted class\n",
        "    top_class_idx = np.argmax(probabilities, axis=1)[0]\n",
        "    top_class_label = class_labels[top_class_idx]\n",
        "    top_class_prob = probabilities[0][top_class_idx]\n",
        "    \n",
        "    return top_class_label, top_class_prob\n",
        "\n",
        "\n",
        "image_tensor = load_onnx_tensor(image_path)\n",
        "class_labels = load_class_labels(json_path)\n",
        "\n",
        "label, prob = onnx_predict(image_tensor.numpy())\n",
        "\n",
        "print(f\"Predicted: {label} ({prob:.2f})\")\n",
        "imshow(image_tensor, title=f'{predicted_label} ({probability:.2f})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "duravit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
