{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "91JqhpJQMmhM"
      },
      "source": [
        "\n",
        "Finetuning Torchvision Models\n",
        "=============================\n",
        "\n",
        "torchvision [models](https://pytorch.org/vision/stable/models.html) and [datasets](https://pytorch.org/vision/stable/datasets.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayI_34cTMmhR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "#from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Helper Functions\n",
        "from libs.config_utils import load_config\n",
        "from libs.model_definitions import initialize_model\n",
        "from libs.train_model import train_model\n",
        "from libs.dataset_utils import get_transforms\n",
        "from libs import splitfolders\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAyt1jy-MmhT"
      },
      "outputs": [],
      "source": [
        "# Load config\n",
        "def ensure_tuple(val, length=None, dtype=None):\n",
        "    # Converts list/int/float to tuple, optionally checks length and dtype\n",
        "    if isinstance(val, (list, np.ndarray)):\n",
        "        val = tuple(val)\n",
        "    elif isinstance(val, (int, float)):\n",
        "        val = (val, val)\n",
        "    if length and len(val) != length:\n",
        "        raise ValueError(f\"Expected tuple of length {length}, got {val}\")\n",
        "    if dtype and not all(isinstance(x, dtype) for x in val):\n",
        "        raise ValueError(f\"Expected tuple of type {dtype}, got {val}\")\n",
        "    return val\n",
        "\n",
        "config_path = 'config.yaml'  # or config.json\n",
        "if not os.path.exists(config_path):\n",
        "    raise FileNotFoundError(f\"Config file not found at {config_path}. Please create one.\")\n",
        "config = load_config(config_path)\n",
        "\n",
        "# Load all experiment settings from config\n",
        "raw_data_dir = config.get('raw_data_dir', None)\n",
        "split_data_dir = config.get('split_data_dir', None)\n",
        "split_ratio = config.get('split_ratio', None)\n",
        "copy_dataset = config.get('copy_dataset', None)\n",
        "dloader_workers = config.get('dloader_workers', 0)\n",
        "\n",
        "model_type = config['model_type']\n",
        "batch_size = config['batch_size']\n",
        "num_epochs = config['num_epochs']\n",
        "learning_rate = config['learning_rate']\n",
        "optimizer_name = config['optimizer_name']\n",
        "train_deep = config['train_deep']\n",
        "add_softmax = config['add_softmax']\n",
        "\n",
        "# Ensure scale_range and input_size are valid tuples for albumentations\n",
        "scale_range = ensure_tuple(config['scale_range'], length=2, dtype=float)\n",
        "input_size = ensure_tuple(config['input_size'], length=2, dtype=int)\n",
        "\n",
        "checkpoints_dir = config['checkpoints_dir']\n",
        "scheduler_type = config['scheduler']\n",
        "scheduler_patience = config['scheduler_patience']\n",
        "scheduler_factor = config['scheduler_factor']\n",
        "early_stopping_patience = config['early_stopping_patience']\n",
        "use_augmentations = config['augmentations']\n",
        "mean = np.array(config['mean'])\n",
        "std = np.array(config['std'])\n",
        "model_list = config['model_list']\n",
        "\n",
        "os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "\n",
        "model_name = model_type\n",
        "checkpoint_path = os.path.join(checkpoints_dir, model_name + \".pth\")\n",
        "json_path = os.path.join(checkpoints_dir, model_name + \"_metadata.json\")\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# check if model_type exists\n",
        "if not model_type in model_list:\n",
        "    print(f\"ERROR: model {model_type} unknown!\")\n",
        "\n",
        "# Flexible optimizer selection\n",
        "def get_optimizer(optimizer_name, params, lr):\n",
        "    if optimizer_name.lower() == 'adam':\n",
        "        return optim.Adam(params, lr=lr)\n",
        "    elif optimizer_name.lower() == 'adamw':\n",
        "        return optim.AdamW(params, lr=lr)\n",
        "    elif optimizer_name.lower() == 'sgd':\n",
        "        return optim.SGD(params, lr=lr, momentum=0.9)\n",
        "    elif optimizer_name.lower() == 'rmsprop':\n",
        "        return optim.RMSprop(params, lr=lr)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure split_data_dir and raw_data_dir are set, fallback to defaults if missing\n",
        "split_data_dir = config.get('split_data_dir')\n",
        "raw_data_dir = config.get('raw_data_dir')\n",
        "\n",
        "split_ratio = config['split_ratio']\n",
        "copy_dataset = config['copy_dataset']\n",
        "\n",
        "# check if dataset is already splitted\n",
        "if not splitfolders.check_existence(split_data_dir, dirs=[\"val\", \"test\", \"train\"]):\n",
        "\n",
        "    # copy or move dataset split into train, validation and test\n",
        "    splitfolders.ratio(raw_data_dir, output=split_data_dir, \n",
        "                       seed=1337, ratio=split_ratio,\n",
        "                       group_prefix=None, \n",
        "                       move=not(copy_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Number of classes in the dataset\n",
        "\n",
        "def count_directories(path):\n",
        "    return len([name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))])\n",
        "\n",
        "num_classes = count_directories(os.path.join(split_data_dir, \"train\"))\n",
        "print(f\"Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------------\n",
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## initialize model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the model for this run\n",
        "model, input_size = initialize_model(model_type, num_classes, train_deep, add_softmax=add_softmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "replace Colab imshow with custom function for use in Jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_tensor_to_array(image, idx=0):\n",
        "    # img = convert_image_to_cv(image, RGB2BGR=False, normalized=True)\n",
        "    img = image.cpu().data[idx].numpy().transpose((1, 2, 0))  # [-1 |  1 ]\n",
        "    img = std * img + mean  # denormalize using config values\n",
        "    img = np.clip(img*255, 0, 255).astype(np.uint8)  # convert to uint8\n",
        "    return img"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G6ozpb87Mmha"
      },
      "source": [
        "### Load Data\n",
        "----------------\n",
        "Now that we know what the input size must be, we can initialize the data\n",
        "transforms, image datasets, and the dataloaders. Notice, the models were\n",
        "pretrained with the hard-coded normalization values, as described\n",
        "`here <https://pytorch.org/docs/master/torchvision/models.html>`__.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugCvPxB_Mmhb"
      },
      "outputs": [],
      "source": [
        "# Data augmentation and normalization for training: http://pytorch.org/vision/main/transforms.html\n",
        "# Use mean and std from config, and enable albumentations if requested\n",
        "\n",
        "data_transforms = get_transforms(input_size, scale_range=scale_range,\n",
        "    hflip=0.5, mean=mean, std=std, use_albumentations=use_augmentations)\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(split_data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=dloader_workers) for x in ['train', 'val']}\n",
        "\n",
        "class_labels = image_datasets['train'].classes\n",
        "print(\"class_labels:\", class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imshow(image, title=None):\n",
        "    if not isinstance(image, np.ndarray):\n",
        "        image = convert_tensor_to_array(image)\n",
        "\n",
        "    ax = plt.subplot(2, 2, 1)\n",
        "    ax.axis('off')\n",
        "    if title:\n",
        "        ax.set_title(title)\n",
        "    plt.imshow(image)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "\n",
        "def visualize_model(model, device=device, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders_dict['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            top_probs, top_labels = torch.max(probabilities, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "\n",
        "                class_label = class_labels[top_labels[j]]\n",
        "                probability = top_probs[j].cpu().numpy()\n",
        "                ax.set_title(f'predicted: {class_label} ({probability:.2f})')\n",
        "\n",
        "                img = convert_tensor_to_array(inputs, idx=j)\n",
        "                plt.imshow(img)\n",
        "            \n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "                \n",
        "        model.train(mode=was_training)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C81WMAgAMmhb"
      },
      "source": [
        "## Create the Optimizer\n",
        "--------------------\n",
        "\n",
        "Now that the model structure is correct, the final step for finetuning\n",
        "and feature extracting is to create an optimizer that only updates the\n",
        "desired parameters. Recall that after loading the pretrained model, but\n",
        "before reshaping, if ``train_deep=False`` we manually set all of the\n",
        "parameter’s ``.requires_grad`` attributes to False. Then the\n",
        "reinitialized layer’s parameters have ``.requires_grad=True`` by\n",
        "default. So now we know that *all parameters that have\n",
        ".requires_grad=True should be optimized.* Next, we make a list of such\n",
        "parameters and input this list to the SGD algorithm constructor.\n",
        "\n",
        "To verify this, check out the printed parameters to learn. When\n",
        "finetuning, this list should be long and include all of the model\n",
        "parameters. However, when feature extracting this list should be short\n",
        "and only include the weights and biases of the reshaped layers.\n",
        "\n",
        "--------------------\n",
        "[using Adam instead of SGD](https://analyticsindiamag.com/ultimate-guide-to-pytorch-optimizers/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oSayW1jMmhb"
      },
      "outputs": [],
      "source": [
        "# Send the model to GPU if possible\n",
        "model = model.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are \n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model.parameters()\n",
        "#print(\"Params to learn:\")\n",
        "if not train_deep:\n",
        "    params_to_update = []\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            #print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            #print(\"\\t\",name)\n",
        "            continue\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = get_optimizer(optimizer_name, params_to_update, learning_rate)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W4gDImEUMmhc"
      },
      "source": [
        "## Run Training and Validation Step\n",
        "--------------------------------\n",
        "\n",
        "Finally, the last step is to setup the loss for the model, then run the\n",
        "training and validation function for the set number of epochs. Notice,\n",
        "depending on the number of epochs this step may take a while on a CPU.\n",
        "Also, the default learning rate is not optimal for all of the models, so\n",
        "to achieve maximum accuracy it would be necessary to tune for each model\n",
        "separately.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEsbBll7Mmhc"
      },
      "outputs": [],
      "source": [
        "# Setup the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Learning rate scheduler (ReduceLROnPlateau on val loss)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer_ft, mode='min', factor=0.5, patience=3, verbose=True\n",
        ")\n",
        "\n",
        "# Early stopping and checkpointing settings\n",
        "early_stopping_patience = 7  # stop if no val loss improvement for 7 epochs\n",
        "checkpoint_best_path = os.path.join(checkpoints_dir, model_name + '_best.pth')\n",
        "os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "\n",
        "starttime = time.time()\n",
        "\n",
        "# Train and evaluate with all modern features\n",
        "model, val_acc_history, val_loss_history = train_model(\n",
        "    model, dataloaders_dict, criterion, optimizer_ft,\n",
        "    num_epochs=num_epochs, device=device,\n",
        "    scheduler=scheduler,\n",
        "    early_stopping_patience=early_stopping_patience,\n",
        "    checkpoint_path=checkpoint_best_path\n",
        ")\n",
        "\n",
        "training_duration = time.time() - starttime\n",
        "\n",
        "best_val_acc = round(float(max(val_acc_history)), 4)\n",
        "last_val_acc = round(float(val_acc_history[-1]), 4)\n",
        "\n",
        "print(\"best_val_acc:\", best_val_acc)\n",
        "print(\"last_val_acc:\", last_val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_model(model, device=device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Checkpoint\n",
        "[saving and loading checkpoints tutorial](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html) , [stackoverflow](https://stackoverflow.com/questions/42703500/how-do-i-save-a-trained-model-in-pytorch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get current date and time as string\n",
        "def get_current_date():\n",
        "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
        "\n",
        "# write model metadata to json file\n",
        "def save_json(data, json_path, update=True):\n",
        "\n",
        "    if update:\n",
        "        with open(json_path) as f:\n",
        "            data_old = json.load(f)\n",
        "        data_old.update(data)\n",
        "        data = data_old\n",
        "    \n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torch.save({\n",
        "#             'epoch': num_epochs,\n",
        "#             'model_state_dict': model.state_dict(),\n",
        "#             'optimizer_state_dict': optimizer_ft.state_dict(),\n",
        "#             'loss': LOSS,\n",
        "#             }, checkpoint_path)\n",
        "\n",
        "\n",
        "torch.save(model, checkpoint_path)\n",
        "\n",
        "\n",
        "# Write variables to a JSON file\n",
        "data = {\n",
        "    'date_created':             get_current_date(),\n",
        "    'model_type':               model_type, \n",
        "    'input_size':               input_size,\n",
        "    'has_softmax':              add_softmax,\n",
        "    'class_labels':             class_labels, \n",
        "    'initial_learning_rate':    learning_rate,\n",
        "    'epochs':                   num_epochs,\n",
        "    'training_time':            training_duration,\n",
        "    'best_val_acc':             best_val_acc,\n",
        "    'last_val_acc':             last_val_acc\n",
        "    }\n",
        "\n",
        "save_json(data, json_path, update=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### convert to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "# # Define the data transformations (same as used during training)\n",
        "# data_transforms = transforms.Compose([\n",
        "#     transforms.Resize(256),\n",
        "#     transforms.CenterCrop(224),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "# ])\n",
        "\n",
        "# Load a sample image from your validation dataset\n",
        "images_dir = os.path.join(split_data_dir, \"val\")\n",
        "image_datasets = datasets.ImageFolder(images_dir, data_transforms[\"val\"])\n",
        "dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=1, shuffle=True)\n",
        "\n",
        "# Get a single batch (one image)\n",
        "inputs, _ = next(iter(dataloader))\n",
        "\n",
        "# Move the model and inputs to the same device (CPU or GPU)\n",
        "model.to(device)\n",
        "inputs = inputs.to(device)\n",
        "\n",
        "\n",
        "onnx_path = os.path.join(checkpoints_dir, model_name + \".onnx\")\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(model, inputs, onnx_path, \n",
        "                  input_names=['input'], output_names=['output'],\n",
        "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------------\n",
        "# Test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Checkpoint and Data Loader\n",
        "\n",
        "[tutorial](https://towardsdatascience.com/how-to-save-and-load-a-model-in-pytorch-with-a-complete-example-c2920e617dee)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 64\n",
        "\n",
        "# # Remember to first initialize the model and optimizer, then load the dictionary locally.\n",
        "# model, input_size = initialize_model(model_type, num_classes, train_deep)\n",
        "# model = model.to(device)\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# checkpoint = torch.load(checkpoint_path)\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# epoch = checkpoint['epoch']\n",
        "# loss = checkpoint['loss']\n",
        "\n",
        "\n",
        "model = torch.load(checkpoint_path)\n",
        "model = model.to(device)\n",
        "model.eval()  # set dropout and batch normalization layers to evaluation mode before running inference\n",
        "\n",
        "\n",
        "# create data loader for test-data\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(input_size),\n",
        "    transforms.CenterCrop(input_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dir = os.path.join(split_data_dir, \"test\")\n",
        "\n",
        "testset = datasets.ImageFolder(test_dir, test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_acc = 0.0\n",
        "for samples, labels in test_loader:\n",
        "    with torch.no_grad():\n",
        "        samples, labels = samples.to(device), labels.to(device)\n",
        "        output = model(samples)\n",
        "\n",
        "        # calculate accuracy\n",
        "        pred = torch.argmax(output, dim=1)\n",
        "        correct = pred.eq(labels)\n",
        "        test_acc += torch.mean(correct.float())\n",
        "\n",
        "testimage_count = len(testset)\n",
        "test_result = test_acc.item()/len(test_loader)\n",
        "print(f'Accuracy of the network on {testimage_count} test images: {round(test_result * 100.0, 2)}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# update metadata with test accuracy\n",
        "data = {'date_modified': get_current_date(), 'test_acc': round(test_result, 2)}\n",
        "save_json(data, json_path, update=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_model(model, device=device, num_images=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------------\n",
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def get_random_image(images_dir, ext=\".jpg\"):\n",
        "    # List all files in the directory\n",
        "    all_files = os.listdir(images_dir)\n",
        "    # Filter out only JPG files\n",
        "    jpg_files = [f for f in all_files if f.endswith(ext)]\n",
        "    # Select a random JPG file\n",
        "    random_image = random.choice(jpg_files)\n",
        "    # Return the full path to the random image\n",
        "    return os.path.join(images_dir, random_image)\n",
        "\n",
        "\n",
        "def load_pt_tensor(image_path, device=\"cpu\"):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_transformed = test_transform(image)  # = data_transforms['val'](image)\n",
        "\n",
        "    # Add a batch dimension and move to CPU/GPU\n",
        "    image_transformed = image_transformed.unsqueeze(0)  \n",
        "    return image_transformed.to(device)\n",
        "\n",
        "\n",
        "# Load class labels from a JSON file\n",
        "def load_class_labels(json_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "        class_labels = json.load(f)[\"class_labels\"]\n",
        "    return class_labels\n",
        "\n",
        "\n",
        "# get a random image from the validation set\n",
        "image_path = get_random_image(os.path.join(split_data_dir, \"val\", \"ants\"))\n",
        "\n",
        "# load class labels from metadata.json\n",
        "class_labels = load_class_labels(json_path)\n",
        "\n",
        "device = torch.device(\"cpu\")  # (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PyTorch inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def torch_predict(model, image, class_labels):\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        outputs = model(image)\n",
        "        \n",
        "        # Get the predicted class and probability\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        top_prob, top_class = probabilities.topk(1, dim=1)\n",
        "        \n",
        "        # Get the predicted class name and probability\n",
        "        class_label = class_labels[top_class[0][0]]\n",
        "        probability = top_prob[0][0].item()\n",
        "    return class_label, probability\n",
        "\n",
        "\n",
        "image_tensor = load_pt_tensor(image_path, device=device)\n",
        "\n",
        "model = torch.load(checkpoint_path)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "predicted_label, probability = torch_predict(model, image_tensor, class_labels)\n",
        "\n",
        "print(f'Predicted: {predicted_label} ({probability:.2f})')\n",
        "imshow(image_tensor, title=f'{predicted_label} ({probability:.2f})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----------\n",
        "### ONNX inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import onnxruntime as ort\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_path = os.path.join(checkpoints_dir, model_name + \".onnx\")\n",
        "ort_session = ort.InferenceSession(onnx_path)\n",
        "\n",
        "\n",
        "# Preprocess the input image\n",
        "def load_onnx_tensor(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image_tensor = test_transform(image)\n",
        "    image_tensor = image_tensor.unsqueeze(0)\n",
        "    return image_tensor\n",
        "\n",
        "\n",
        "# Run inference\n",
        "def onnx_predict(input_batch):\n",
        "    ort_inputs = {ort_session.get_inputs()[0].name: input_batch}\n",
        "    ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "    # Convert logits to probabilities\n",
        "    logits = ort_outs[0]\n",
        "    probabilities = F.softmax(torch.tensor(logits), dim=1).numpy()\n",
        "    \n",
        "    # Get the top predicted class\n",
        "    top_class_idx = np.argmax(probabilities, axis=1)[0]\n",
        "    top_class_label = class_labels[top_class_idx]\n",
        "    top_class_prob = probabilities[0][top_class_idx]\n",
        "    \n",
        "    return top_class_label, top_class_prob\n",
        "\n",
        "\n",
        "image_tensor = load_onnx_tensor(image_path)\n",
        "class_labels = load_class_labels(json_path)\n",
        "\n",
        "label, prob = onnx_predict(image_tensor.numpy())\n",
        "\n",
        "print(f\"Predicted: {label} ({prob:.2f})\")\n",
        "imshow(image_tensor, title=f'{predicted_label} ({probability:.2f})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
