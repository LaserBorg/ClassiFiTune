{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "91JqhpJQMmhM"
      },
      "source": [
        "\n",
        "Finetuning Torchvision Models\n",
        "=============================\n",
        "\n",
        "torchvision [models](https://pytorch.org/vision/stable/models.html) and [datasets](https://pytorch.org/vision/stable/datasets.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayI_34cTMmhR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Helper Functions\n",
        "from libs.torchvision.torchvision_models import initialize_model\n",
        "from libs.torchvision.torchvision_train import train_model\n",
        "from libs import splitfolders\n",
        "from libs.common import load_dict, dump_dict, date2string, ensure_tuple, tensor_to_array\n",
        "from libs.albumentations_utils import get_transforms\n",
        "\n",
        "#from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAyt1jy-MmhT"
      },
      "outputs": [],
      "source": [
        "settings = load_dict('settings_torchvision.yaml')\n",
        "\n",
        "# Load all experiment settings from settings\n",
        "raw_data_dir = settings.get('raw_data_dir', None)\n",
        "split_data_dir = settings.get('split_data_dir', None)\n",
        "split_ratio = settings.get('split_ratio', None)\n",
        "copy_dataset = settings.get('copy_dataset', None)\n",
        "dloader_workers = settings.get('dloader_workers', 0)\n",
        "\n",
        "model_type = settings['model_type']\n",
        "batch_size = settings['batch_size']\n",
        "num_epochs = settings['num_epochs']\n",
        "learning_rate = float(settings['learning_rate'])\n",
        "optimizer_name = settings['optimizer_name']\n",
        "train_deep = settings['train_deep']\n",
        "add_softmax = settings['add_softmax']\n",
        "\n",
        "# Ensure scale_range and input_size are valid tuples for albumentations\n",
        "scale_range = ensure_tuple(settings['scale_range'], length=2, dtype=float)\n",
        "input_size = ensure_tuple(settings['input_size'], length=2, dtype=int)\n",
        "\n",
        "output_dir = settings['output_dir']\n",
        "scheduler_type = settings['scheduler']\n",
        "scheduler_patience = settings['scheduler_patience']\n",
        "scheduler_factor = settings['scheduler_factor']\n",
        "early_stopping_patience = settings['early_stopping_patience']\n",
        "use_augmentations = settings['augmentations']\n",
        "\n",
        "mean = np.array(settings['mean'])  # np.array(IMAGENET_DEFAULT_MEAN)\n",
        "std = np.array(settings['std'])    # np.array(IMAGENET_DEFAULT_STD)\n",
        "\n",
        "model_list = settings['model_list']\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "model_name = model_type\n",
        "output_path = os.path.join(output_dir, model_name + \".pth\")\n",
        "json_path = os.path.join(output_dir, model_name + \"_metadata.json\")\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# check if model_type exists\n",
        "if not model_type in model_list:\n",
        "    print(f\"ERROR: model {model_type} unknown!\")\n",
        "\n",
        "# Flexible optimizer selection\n",
        "def get_optimizer(optimizer_name, params, lr):\n",
        "    if optimizer_name.lower() == 'adam':\n",
        "        return optim.Adam(params, lr=lr)\n",
        "    elif optimizer_name.lower() == 'adamw':\n",
        "        return optim.AdamW(params, lr=lr)\n",
        "    elif optimizer_name.lower() == 'sgd':\n",
        "        return optim.SGD(params, lr=lr, momentum=0.9)\n",
        "    elif optimizer_name.lower() == 'rmsprop':\n",
        "        return optim.RMSprop(params, lr=lr)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure split_data_dir and raw_data_dir are set, fallback to defaults if missing\n",
        "split_data_dir = settings.get('split_data_dir')\n",
        "raw_data_dir = settings.get('raw_data_dir')\n",
        "\n",
        "split_ratio = settings['split_ratio']\n",
        "copy_dataset = settings['copy_dataset']\n",
        "\n",
        "# check if dataset is already splitted\n",
        "if not splitfolders.check_existence(split_data_dir, dirs=[\"val\", \"test\", \"train\"]):\n",
        "\n",
        "    # copy or move dataset split into train, validation and test\n",
        "    splitfolders.ratio(raw_data_dir, output=split_data_dir, \n",
        "                       seed=1337, ratio=split_ratio,\n",
        "                       group_prefix=None, \n",
        "                       move=not(copy_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Number of classes in the dataset\n",
        "\n",
        "def count_directories(path):\n",
        "    return len([name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))])\n",
        "\n",
        "num_classes = count_directories(os.path.join(split_data_dir, \"train\"))\n",
        "print(f\"Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------------\n",
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## initialize model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the model for this run\n",
        "model, input_size = initialize_model(model_type, num_classes, train_deep, add_softmax=add_softmax)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G6ozpb87Mmha"
      },
      "source": [
        "### Load Data\n",
        "----------------\n",
        "Now that we know what the input size must be, we can initialize the data\n",
        "transforms, image datasets, and the dataloaders. Notice, the models were\n",
        "pretrained with the hard-coded normalization values, as described\n",
        "`here <https://pytorch.org/docs/master/torchvision/models.html>`__.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugCvPxB_Mmhb"
      },
      "outputs": [],
      "source": [
        "# Data augmentation and normalization for training: http://pytorch.org/vision/main/transforms.html\n",
        "# Use mean and std from settings, and enable albumentations if requested\n",
        "\n",
        "data_transforms = get_transforms(input_size, scale_range=scale_range, hflip=0.5, mean=mean, std=std)\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(split_data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=dloader_workers) for x in ['train', 'val']}\n",
        "\n",
        "class_labels = image_datasets['train'].classes\n",
        "print(\"class_labels:\", class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_model(model, device=device, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders_dict['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            top_probs, top_labels = torch.max(probabilities, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "\n",
        "                class_label = class_labels[top_labels[j]]\n",
        "                probability = top_probs[j].cpu().numpy()\n",
        "                ax.set_title(f'predicted: {class_label} ({probability:.2f})')\n",
        "\n",
        "                # Fix: Call the function with proper arguments\n",
        "                img = tensor_to_array(inputs, idx=j, mean=mean, std=std)\n",
        "                plt.imshow(img)\n",
        "            \n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "                \n",
        "        model.train(mode=was_training)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C81WMAgAMmhb"
      },
      "source": [
        "## Create the Optimizer\n",
        "--------------------\n",
        "\n",
        "Now that the model structure is correct, the final step for finetuning\n",
        "and feature extracting is to create an optimizer that only updates the\n",
        "desired parameters. Recall that after loading the pretrained model, but\n",
        "before reshaping, if ``train_deep=False`` we manually set all of the\n",
        "parameter’s ``.requires_grad`` attributes to False. Then the\n",
        "reinitialized layer’s parameters have ``.requires_grad=True`` by\n",
        "default. So now we know that *all parameters that have\n",
        ".requires_grad=True should be optimized.* Next, we make a list of such\n",
        "parameters and input this list to the SGD algorithm constructor.\n",
        "\n",
        "To verify this, check out the printed parameters to learn. When\n",
        "finetuning, this list should be long and include all of the model\n",
        "parameters. However, when feature extracting this list should be short\n",
        "and only include the weights and biases of the reshaped layers.\n",
        "\n",
        "--------------------\n",
        "[using Adam instead of SGD](https://analyticsindiamag.com/ultimate-guide-to-pytorch-optimizers/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oSayW1jMmhb"
      },
      "outputs": [],
      "source": [
        "# Send the model to GPU if possible\n",
        "model = model.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are \n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model.parameters()\n",
        "#print(\"Params to learn:\")\n",
        "if not train_deep:\n",
        "    params_to_update = []\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            #print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            #print(\"\\t\",name)\n",
        "            continue\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = get_optimizer(optimizer_name, params_to_update, learning_rate)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W4gDImEUMmhc"
      },
      "source": [
        "## Run Training and Validation Step\n",
        "--------------------------------\n",
        "\n",
        "Finally, the last step is to setup the loss for the model, then run the\n",
        "training and validation function for the set number of epochs. Notice,\n",
        "depending on the number of epochs this step may take a while on a CPU.\n",
        "Also, the default learning rate is not optimal for all of the models, so\n",
        "to achieve maximum accuracy it would be necessary to tune for each model\n",
        "separately.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEsbBll7Mmhc"
      },
      "outputs": [],
      "source": [
        "# Setup the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Learning rate scheduler (ReduceLROnPlateau on val loss)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "# Early stopping and checkpointing settings\n",
        "early_stopping_patience = 7  # stop if no val loss improvement for 7 epochs\n",
        "checkpoint_best_path = os.path.join(output_dir, model_name + '_best.pth')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "starttime = time.time()\n",
        "\n",
        "# Train and evaluate with all modern features\n",
        "model, val_acc_history, val_loss_history = train_model(\n",
        "    model, dataloaders_dict, criterion, optimizer_ft,\n",
        "    num_epochs=num_epochs, device=device,\n",
        "    scheduler=scheduler,\n",
        "    early_stopping_patience=early_stopping_patience,\n",
        "    checkpoint_path=checkpoint_best_path\n",
        ")\n",
        "\n",
        "training_duration = time.time() - starttime\n",
        "\n",
        "best_val_acc = round(float(max(val_acc_history)), 4)\n",
        "last_val_acc = round(float(val_acc_history[-1]), 4)\n",
        "\n",
        "print(\"best_val_acc:\", best_val_acc)\n",
        "print(\"last_val_acc:\", last_val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_model(model, device=device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Checkpoint\n",
        "[saving and loading checkpoints tutorial](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html) , [stackoverflow](https://stackoverflow.com/questions/42703500/how-do-i-save-a-trained-model-in-pytorch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torch.save({\n",
        "#             'epoch': num_epochs,\n",
        "#             'model_state_dict': model.state_dict(),\n",
        "#             'optimizer_state_dict': optimizer_ft.state_dict(),\n",
        "#             'loss': LOSS,\n",
        "#             }, output_path)\n",
        "\n",
        "torch.save(model, output_path)\n",
        "\n",
        "\n",
        "# Write variables to a JSON file\n",
        "data = {\n",
        "    'date_created':             date2string(),\n",
        "    'model_type':               model_type, \n",
        "    'input_size':               input_size,\n",
        "    'has_softmax':              add_softmax,\n",
        "    'class_labels':             class_labels, \n",
        "    'initial_learning_rate':    learning_rate,\n",
        "    'epochs':                   num_epochs,\n",
        "    'training_time':            training_duration,\n",
        "    'best_val_acc':             best_val_acc,\n",
        "    'last_val_acc':             last_val_acc\n",
        "    }\n",
        "\n",
        "dump_dict(data, json_path, update=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### convert to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "# # Define the data transformations (same as used during training)\n",
        "# data_transforms = transforms.Compose([\n",
        "#     transforms.Resize(256),\n",
        "#     transforms.CenterCrop(224),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "# ])\n",
        "\n",
        "# Load a sample image from your validation dataset\n",
        "images_dir = os.path.join(split_data_dir, \"val\")\n",
        "image_datasets = datasets.ImageFolder(images_dir, data_transforms[\"val\"])\n",
        "dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=1, shuffle=True)\n",
        "\n",
        "# Get a single batch (one image)\n",
        "inputs, _ = next(iter(dataloader))\n",
        "\n",
        "# Move the model and inputs to the same device (CPU or GPU)\n",
        "model.to(device)\n",
        "inputs = inputs.to(device)\n",
        "\n",
        "\n",
        "onnx_path = os.path.join(output_dir, model_name + \".onnx\")\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(\n",
        "    model, inputs, onnx_path,\n",
        "    input_names=['input'], output_names=['output'],\n",
        "    dynamic_shapes=[{0: 'batch'}],\n",
        "    dynamo=True,\n",
        "    external_data=False  # don't save data as a second file\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------------\n",
        "# Test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Checkpoint and Data Loader\n",
        "\n",
        "[tutorial](https://towardsdatascience.com/how-to-save-and-load-a-model-in-pytorch-with-a-complete-example-c2920e617dee)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 64\n",
        "\n",
        "# # Remember to first initialize the model and optimizer, then load the dictionary locally.\n",
        "# model, input_size = initialize_model(model_type, num_classes, train_deep)\n",
        "# model = model.to(device)\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# checkpoint = torch.load(output_path)\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# epoch = checkpoint['epoch']\n",
        "# loss = checkpoint['loss']\n",
        "\n",
        "\n",
        "# Allowlist EfficientNet for unpickling if you trust the source\n",
        "import torch.serialization\n",
        "torch.serialization.add_safe_globals([torchvision.models.efficientnet.EfficientNet])\n",
        "\n",
        "model = torch.load(output_path, weights_only=False)\n",
        "model = model.to(device)\n",
        "model.eval()  # set dropout and batch normalization layers to evaluation mode before running inference\n",
        "\n",
        "\n",
        "# create data loader for test-data\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(input_size),\n",
        "    transforms.CenterCrop(input_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dir = os.path.join(split_data_dir, \"test\")\n",
        "\n",
        "testset = datasets.ImageFolder(test_dir, test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_acc = 0.0\n",
        "for samples, labels in test_loader:\n",
        "    with torch.no_grad():\n",
        "        samples, labels = samples.to(device), labels.to(device)\n",
        "        output = model(samples)\n",
        "\n",
        "        # calculate accuracy\n",
        "        pred = torch.argmax(output, dim=1)\n",
        "        correct = pred.eq(labels)\n",
        "        test_acc += torch.mean(correct.float())\n",
        "\n",
        "testimage_count = len(testset)\n",
        "test_result = test_acc.item()/len(test_loader)\n",
        "print(f'Accuracy of the network on {testimage_count} test images: {round(test_result * 100.0, 2)}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# update metadata with test accuracy\n",
        "data = {'date_modified': date2string(), 'test_acc': round(test_result, 2)}\n",
        "dump_dict(data, json_path, update=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_model(model, device=device, num_images=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py313",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
